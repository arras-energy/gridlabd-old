#!/usr/local/bin/python3
"""Syntax: gridlabd geodata OPTIONS DIRECTIVE [ARGUMENTS]

The geodata command gathers and joins geographic data. The geodata subcommand
uses directives that are documented in the DIRECTIVES section below.

In general geodata is used to acquire geographic information at a location or
along a specified path. This information includes ground elevation, vegetation
characteristics, weather, census, building, and transportation data.  The
specific data sets and their origins are described in the DATASETS section
below.

OPTIONS

  [-c|--cache FOLDER]         change cache folder
  [-C|--config FILE]          change config file
  [-d|--debug]                enable debug output
  [-f|--format FORMAT]        change output format
  [-j|--join TYPE]            control how dataset joins with input path
  [-k|--key KEY]              change method for generating keys
  [-o|--output CSVOUT]        output to CSVOUT
  [-q|--quiet]                disable normal output
  [-s|--silent]               disable error output
  [-T|--threadcount THREADS]  change maximum thread count
  [-v|--verbose]              enable verbose output
  [-w|--warning]              disable warning output

REMARKS

The default cache folder is /usr/local/share/gridlabd/geodata. The default
config file $HOME/.gridlabd/geodata-config. The default maximum thread count
is 1.

DIRECTIVES

The following directives are available:

  config get PARAMETER config set PARAMETER VALUE config show [PATTERN]

    The config directive changes values in the config file.

  append [ARGUMENTS]

    The append directive generates a new column with data from the specified
    dataset. An error occurs if a column exists.

  update [ARGUMENTS]

    The update directive updates an existing column with data from the specified
    dataset. An error occurs if a column does not exist.

  merge [ARGUMENTS]

    The merge diretive merges the results from the specified dataset with the
    data.  If a column exists, it is updated. If a column does not exist, it is
    created.

ARGUMENTS

All directives support the following arguments

  [-D|--dataset] NAME

    Specifies the dataset from which the geographic information is to be
    acquired. See the DATASETS section below for details.

  [-o|--output] CSVOUT

    Normally the output is written to /dev/stdout. When CSVOUT is specified the
    output data is written to the specified file. If the output file already
    exists, it is overwritten with the new data.

  --resolution METERS

    Specifies the resolution in meters of the data to be generated along the path.
    If omitted, the output is generated only at the locations listed in the input.
    This option has no meaning for the location directive.

KEYS

The [-k|--key KEY] options changes how row keys are generated. The default is
no key, in which case there is no guarantee that the rows will be output in the
same order in which they were input.

  [-k|--key location]

    The location key computes geohash codes. Rows are indexed on the key named
    "location".

  [-k|--key position]

    The position key performs a distance calculation with respect to the first
    entry in the data, thus maintaining the ordering the rows.  Rows are indexed
    on the key names "position". The default

If the [--resolution METERS] option is used, the keys are generated at
the specified resolution along the path. The default resolution is 1 meter. This
is only supported with datasets for which the path option is available.

DATASETS

The following datasets are available. To specify a layer, use the syntax
"NAME.LAYER".  Multiple datasets and layers may be specified using a
comma-delimited list.

  building

    The building dataset provides build environment data from NREL. Available
    layers are "building_type" and "building_size".

  census

    The census dataset provides economic and population data from the US Census
    Bureau.

  distance

    The distance dataset calculates the distance between each point and the
    point before it.

  elevation

    The elevation dataset provides 1 arcsecond resolution ground elevation data
    from the USGS.

  powerline

    The powerline dataset provides powerline geometry calculations based on
    the GridLAB-D cable library.

  transportation

    The transportation dataset provides mobility data from traffic data services.
    You must subscribe to the TrafficView service to use this dataset.

  utility

    The utility data provides data about the utility servicing the locations.

  vegetation

    The vegetation dataset provides 7 layers of data about vegetation.  Available
    layers are "canopy_cover", "canopy_height", "base_height", "bulk_density",
    "layer_count", "fuel_density", and "surface_fuels".. You must subscribe to the
    Forest Observatory service to use this dataset.

  weather

    The weather dataset provides historical, current, and short term forecasts of
    dry bulk, wet bulb, solar, and wind data from NOAA.

FORMATS

Output is generated by default in CSV format.  Other output formats may be
selected as follows:

  JSON           all available data is generated in JSON format

  RAW            the DATASET field is generated as a raw string

  POS            the LAT,LON tuple is generated as a raw string

  FIELD:<name>   the selected field is generated as a raw string

DEVELOPER API

Packages must implement the following (TODO indicates where your code goes)

    version = 1

    default_options = {
        TODO,
    }

    default_config = {
        TODO,
    }

    def apply(data, options=default_options, config=default_config):
        result = TODO
        return pandas.DataFrame(result)

    if __name__ == '__main__':
        if len(sys.argv) == 1 or sys.argv[1] in ["-h","--help","help"]:
            print(f"Syntax: {sys.argv[0].split('/')[-1]} [unittest|makeconfig]")
        elif sys.argv[1] in ["unittest"]:
            import unittest
            class TestAddress(unittest.TestCase):
                def test_1(self):
                    TODO
            unittest.main()
        elif sys.argv[1] in ["makeconfig"]:
            with open(sys.argv[0].replace(".py",".cfg"),"w") as fh:
                json.dump(default_config,fh,indent=4)
        else:
            raise Exception(f"'{sys.argv[0]}' is an invalid command option")

See geodata_distance.py for a simple example.
"""
import sys, os
import importlib
from importlib import util
import json
import math, numpy
import pandas

NAME = "geodata"
GEODATA = sys.modules[__name__]
DIRECTIVES = ["config","update","merge","append"]
VERBOSE = False
DEBUG = False
SILENT = False
QUIET = False
DEBUG = False
CFGFILE = f"os.getenv('HOME')/.gridlabd/geodata.conf"
GEODATAURL = "http://geodata.gridlabd.us/"
MAXTHREADS = 1
DATASET = None
OUTPUT = "/dev/stdout"
INPUT = "/dev/stdin"
RESOLUTION = None
MODULE = None
CONFIGDATA = {}
PKGDATA = os.getenv("GLD_ETC")
if not PKGDATA:
    PKGDATA = "/usr/local/share/gridlabd"
FORMAT = "CSV"
PATHJOIN = "outer"
CONFIGDIR = {
    "system" : PKGDATA + "/geodata",
    "user" : os.getenv("HOME") + "/.gridlabd/geodata",
    "local" : os.getenv("PWD"),
}
IDPRECISION = 0
GEOPRECISION = 4
KEYINDEX = None

E_OK = 0
E_SYNTAX = 1
E_NOTFOUND = 2


def error(msg,exitcode=None):
    text = f"ERROR [{NAME}/{DATASET}]: {msg}"
    if DEBUG:
        raise Exception(msg)
    if not SILENT:
        print(text,file=sys.stderr,flush=True)
    if exitcode:
        exit(exitcode)

def warning(msg):
    if not QUIET:
        text = f"WARNING [{NAME}/{DATASET}]: {msg}"
        print(text,file=sys.stderr)

def verbose(msg):
    if VERBOSE:
        text = f"VERBOSE [{NAME}/{DATASET}]: {msg}"
        print(text,file=sys.stderr)

def output(msg):
    if not QUIET:
        print(msg,file=sys.stdout)

def debug(msg):
    if DEBUG:
        print(f"DEBUG [{NAME}/{DATASET}]: {msg}", file=sys.stderr)

python_help = help
def help(dataset=None):
    if dataset:
        MODULE = load_dataset(dataset)
        if MODULE:
            python_help(MODULE.__name__)
        else:
            error(f"command '{command}' not found",E_SYNTAX)
    else:
        python_help(__name__)
    return None, None

def syntax():
    print(__doc__.split("\n")[0],file=sys.stdout)

def ids(data):
    lats = data["latitude"]
    lons = data["longitude"]
    return distance([list(a) for a in zip(lats,lons)])

#
# GEOHASH support
#
from math import log10

#  Note: the alphabet in geohash differs from the common base32
#  alphabet described in IETF's RFC 4648
#  (http://tools.ietf.org/html/rfc4648)
__base32 = '0123456789bcdefghjkmnpqrstuvwxyz'
__decodemap = { }
for i in range(len(__base32)):
    __decodemap[__base32[i]] = i
del i

def decode_exactly(geohash):
    """
    Decode the geohash to its exact values, including the error
    margins of the result.  Returns four float values: latitude,
    longitude, the plus/minus error for latitude (as a positive
    number) and the plus/minus error for longitude (as a positive
    number).
    """
    lat_interval, lon_interval = (-90.0, 90.0), (-180.0, 180.0)
    lat_err, lon_err = 90.0, 180.0
    is_even = True
    for c in geohash:
        cd = __decodemap[c]
        for mask in [16, 8, 4, 2, 1]:
            if is_even: # adds longitude info
                lon_err /= 2
                if cd & mask:
                    lon_interval = ((lon_interval[0]+lon_interval[1])/2, lon_interval[1])
                else:
                    lon_interval = (lon_interval[0], (lon_interval[0]+lon_interval[1])/2)
            else:      # adds latitude info
                lat_err /= 2
                if cd & mask:
                    lat_interval = ((lat_interval[0]+lat_interval[1])/2, lat_interval[1])
                else:
                    lat_interval = (lat_interval[0], (lat_interval[0]+lat_interval[1])/2)
            is_even = not is_even
    lat = (lat_interval[0] + lat_interval[1]) / 2
    lon = (lon_interval[0] + lon_interval[1]) / 2
    return lat, lon, lat_err, lon_err

def decode(geohash):
    """
    Decode geohash, returning two strings with latitude and longitude
    containing only relevant digits and with trailing zeroes removed.
    """
    lat, lon, lat_err, lon_err = decode_exactly(geohash)
    # Format to the number of decimals that are known
    lats = "%.*f" % (max(1, int(round(-log10(lat_err)))) - 1, lat)
    lons = "%.*f" % (max(1, int(round(-log10(lon_err)))) - 1, lon)
    if '.' in lats: lats = lats.rstrip('0')
    if '.' in lons: lons = lons.rstrip('0')
    return lats, lons

def encode(latitude, longitude, precision=12):
    """
    Encode a position given in float arguments latitude, longitude to
    a geohash which will have the character count precision.
    """
    lat_interval, lon_interval = (-90.0, 90.0), (-180.0, 180.0)
    geohash = []
    bits = [ 16, 8, 4, 2, 1 ]
    bit = 0
    ch = 0
    even = True
    while len(geohash) < precision:
        if even:
            mid = (lon_interval[0] + lon_interval[1]) / 2
            if longitude > mid:
                ch |= bits[bit]
                lon_interval = (mid, lon_interval[1])
            else:
                lon_interval = (lon_interval[0], mid)
        else:
            mid = (lat_interval[0] + lat_interval[1]) / 2
            if latitude > mid:
                ch |= bits[bit]
                lat_interval = (mid, lat_interval[1])
            else:
                lat_interval = (lat_interval[0], mid)
        even = not even
        if bit < 4:
            bit += 1
        else:
            geohash += __base32[ch]
            bit = 0
            ch = 0
    return ''.join(geohash)

def get_latlon(pos):
    try:
        latlon = pos.split(",")
        lat = float(latlon[0])
        lon = float(latlon[1])
        if -90 <= lat <= 90 and -180 <= lon <= 180:
            debug(f"get_latlon(pos={pos}) --> {lat},{lon}")
            return lat,lon
        else:
            return None, None
    except:
        return None, None

def set_location(data):
    try:
        data["location"] = list(map(lambda pos: encode(pos[0],pos[1]),zip(data["latitude"],data["longitude"])))
        data.set_index("location",inplace=True)
    except:
        pass
    return data

def dataframe_to_table(data):
    table = f"{data}"
    rule = "-"*max(map(lambda x:len(x),table.split("\n")))
    return f"\n{rule}\n{table}\n{rule}\n"

def set_index(data):
    debug(f"set_index(data={dataframe_to_table(data)})")
    if data.index.name == KEYINDEX:
        return data
    if KEYINDEX == "location":
        set_location(data)
    elif KEYINDEX == "position":
        set_position(data)
    elif not type(KEYINDEX) is type(None):
        data.set_index(KEYINDEX,inplace=True)
    else:
        data.reset_index(inplace=True)
    return data

def get_args(args):
    data = []
    options = MODULE.default_options
    config = CONFIGDATA
    config.update(MODULE.default_config)
    for arg in args:
        lat,lon = get_latlon(arg)
        if arg[0:2] == "--" and len(arg) > 2:
            opts = arg[2:].split("=")
        else:
            opts = [None]
        if opts[0] in config.keys():
            if len(opts) == 1:
                config[opts[0]] = not config[opts[0]]
            else:
                config[opts[0]] = type(config[opts[0]])(opts[1])
        elif opts[0] in options.keys():
            if len(opts) == 1:
                options[opts[0]] = not options[opts[0]]
            else:
                options[opts[0]] = type(options[opts[0]])(opts[1])
        elif type(lat) == float and type(lon) == float:
            data.append(pandas.DataFrame({"latitude":[lat],"longitude":[lon]}))
        elif os.path.exists(arg):
            data.append(pandas.read_csv(arg))
        else:
            data.append(pandas.DataFrame({DATASET:[arg]}))
    data = pandas.concat(data,ignore_index=True)
    if "resolution" in options:
        data = get_path(data,options["resolution"])
    set_index(data)
    debug(f"get_args(args={args}) -->{dataframe_to_table(data)}options = {options}\nconfig = {config}")
    return data,options,config

def merge(args):
    data,options,config = get_args(args)
    debug(f"{DATASET}.apply(data={dataframe_to_table(data)}options = {options}\nconfig = {config})")
    try:
        result = MODULE.apply(data,options,config)
    except Exception as err:
        error(err)
        result = None
    set_index(data)
    debug(f"  --> {OUTPUT}\n{result}")
    return result, OUTPUT

def set_position(data):
    data["position"] = pandas.Series(data["distance"]*10**IDPRECISION,dtype="int32")
    return data.set_index("position").sort_index()

def get_path(data,resolution):
    if resolution < 0.0:
        error(f"get_path(data={dataframe_to_table(data)},resolution={resolution}): negative resolution is invalid",E_SYNTAX)
    if resolution == 0.0:
        return data
    path = {"distance":[],"latitude":[],"longitude":[],"heading":[]}
    last = None
    post = 0.0
    for pos in list(zip(data["latitude"],data["longitude"])):
        lat = pos[0]
        lon = pos[1]
        if last:
            dist = get_distance(pos,last)
            head = (270-numpy.arctan2(last[0]-pos[0],last[1]-pos[1])*180/math.pi)%360
            if resolution < dist:
                segs = dist/resolution
            else:
                segs = 1
            dlat = (lat-last[0])/segs
            dlon = (lon-last[1])/segs
        else:
            dist = 0.0
            head = float('nan')
        while dist > resolution:
            lat += dlat
            lon += dlon
            post += resolution
            path["distance"].append(post)
            path["heading"].append(head)
            path["latitude"].append(lat)
            path["longitude"].append(lon)
            dist -= resolution
        post += dist
        path["distance"].append(post)
        path["heading"].append(head)
        path["latitude"].append(pos[0])
        path["longitude"].append(pos[1])
        last = pos
    path = set_position(pandas.DataFrame(path))
    joinon = ["position"]
    for other in ["latitude","longitude","location"]:
        if other in data.columns:
            joinon.append(other)
    debug(f"joinon = {joinon}")
    debug(f"data =\n{dataframe_to_table(data)}")
    debug(f"path =\n{dataframe_to_table(path)}")
    #result = data.reset_index().join(path.reset_index(),on=joinon,how=PATHJOIN,sort=True)
    result = data.merge(path,how=PATHJOIN)
    debug(f"result =\n{dataframe_to_table(result)}")
    return set_position(result)

def get_distance(pos1,pos2):
    """Compute haversine distances along a path
    ARGUMENTS

        path ((lat,lon) tuple) Specifies the path along which the distance is
                            computed

    RETURNS

        list   The cumulative distances along the path
    """
    lat1 = pos1[0]*math.pi/180
    lat2 = pos2[0]*math.pi/180
    lon1 = pos1[1]*math.pi/180
    lon2 = pos2[1]*math.pi/180
    a = math.sin((lat2-lat1)/2)**2+math.cos(lat1)*math.cos(lat2)*math.sin((lon2-lon1)/2)**2
    return 6371e3*(2*numpy.arctan2(numpy.sqrt(a),numpy.sqrt(1-a)))

def main(argc,argv):
    global PKGDATA
    global DATASET
    global FORMAT
    n = 1
    DIRECTIVE = []
    if not PKGDATA or not os.path.exists(PKGDATA):
        warning("package folder '{PKGDATA}' not found, using default /usr/local/share/gridlabd")
        PKGDATA = "/usr/local/share/gridlabd"
    while n < len(argv):
        if argv[n] in ["-c","-cache"]:
            global CACHE
            n += 1
            CACHE = argv[n]
            if not os.path.exists(CACHE):
                warning(f"cache folder '{CACHE}' does not exist")
            else:
                verbose(f"using cache folder '{CACHE}'")
        elif argv[n] in ["-C","--configfile"]:
            global CFGFILE
            n += 1
            CFGFILE = argv[n]
            if not os.path.exists(CFGFILE):
                warning(f"config file '{CFGFILE}' does not exist")
            else:
                verbose(f"using GLM file {GLMFILE}")
        elif argv[n] in ["-d","--debug"]:
            global DEBUG
            DEBUG = True
            verbose("debug output enabled")
        elif argv[n] in ["-D","--dataset"]:
            n += 1
            DATASET = argv[n]
            load_dataset([DATASET])
        elif argv[n] in ["-f","--format"]:
            n += 1
            if not argv[n] in ["CSV","RAW","JSON","POS"] and not argv[n].startswith("FIELD:"):
                error(f"format '{argv[n]}' is not recognized",E_SYNTAX)
            FORMAT = argv[n]
            verbose(f"output format is set to '{FORMAT}'")
        elif argv[n] in ["-h","--help"]:
            help()
            exit(E_OK)
        elif argv[n] in ["-j","--join"]:
            global PATHJOIN
            n += 1
            if not argv[n] in ["inner","outer","left","right"]:
                error(f"path join '{argv[n]}' is not valid",E_SYNTAX)
            PATHJOIN = argv[n]
            verbose(f"path join is set to '{PATHJOIN}'")
        elif argv[n] in ["-k","--key"]:
            global KEYINDEX
            n += 1
            KEYINDEX = argv[n]
            verbose(f"key index is set to '{KEYINDEX}'")
        elif argv[n] in ["-o","--output"]:
            global OUTPUT
            n += 1
            OUTPUT = argv[n]
            verbose(f"output is set to '{OUTPUT}'")
        elif argv[n] in ["-q","--quiet"]:
            global QUIET
            QUIET = True
            verbose("quiet output enabled")
        elif argv[n] in ["-s","--silent"]:
            global SILENT
            SILENT = True
            verbose("silent output enabled")
        elif argv[n] in ["-T","--threadcount"]:
            global MAXTHREADS
            n += 1
            MAXTHREADS = int(argv[n])
            verbose(f"maximum thread count {MAXTHREADS}")
        elif argv[n] in ["-v","--verbose"]:
            global VERBOSE
            VERBOSE = True
            verbose("verbose output enabled")
        elif argv[n] in ["-w","--warning"]:
            global WARNING
            WARNING = False
            verbose("warning output disable")
        else:
            DIRECTIVE.append(argv[n])
        n += 1
    if len(DIRECTIVE) == 0:
        syntax()
        exit(E_SYNTAX)
    elif len(DIRECTIVE) == 1:
        args = []
    else:
        args = DIRECTIVE[1:]
    if DIRECTIVE[0] == "help":
        help(args)
        exit(E_OK)
    elif not DIRECTIVE[0] in DIRECTIVES:
        error(f"directive '{DIRECTIVE[0]}' is not valid",E_SYNTAX)
    data, savefile = globals()[DIRECTIVE[0]](args)
    if type(data) is pandas.DataFrame and savefile:
        if FORMAT == "CSV":
            data.to_csv(savefile)
        elif FORMAT == "RAW":
            print(" ".join(list(map(lambda x:str(x),data[DATASET].to_list()))))
        elif FORMAT == "JSON":
            print(data.to_json(orient="records"))
        elif FORMAT == "POS":
            lats = data["latitude"].to_list()
            lons = data["longitude"].to_list()
            pos = list(zip(lats,lons))
            print(" ".join(list(map(lambda x:f"{numpy.round(x[0],GEOPRECISION)},{numpy.round(x[1],GEOPRECISION)}",pos))))
        elif FORMAT.startswith("FIELD:"):
            specs = FORMAT.split(":")
            try:
                columns = []
                def quote(x):
                    x = str(x)
                    if "," in x:
                        return f"\"{x}\""
                    else:
                        return x
                for field in specs[1].split(","):
                    columns.append(list(map(lambda x:quote(x),data[field].to_list())))
                for row in numpy.array(columns).transpose():
                    print(",".join(row))
            except:
                error(f"format 'FIELD.{specs[1]}' is invalid or field not found",E_NOTFOUND)
        else:
            error(f"format '{FORMAT}' is invalid",E_SYNTAX)

def load_dataset(args):
    global DATASET
    global PKGDATA
    global MODULE
    DATASET=args[0]
    location = f"{PKGDATA}/geodata_{DATASET}.py"
    if not os.path.exists(location):
        error(f"dataset '{DATASET}' module is not found in '{location}'",E_NOTFOUND)
    verbose(f"dataset '{DATASET}' selected")
    modspec = util.spec_from_file_location(DATASET, location)
    global MODULE
    MODULE = importlib.import_module(f"geodata_{DATASET}")
    if not MODULE:
        error(f"unable to import module geodata_{DATASET} from {location}",E_NOTFOUND)
    if hasattr(MODULE,"set_context"):
        MODULE.set_context(sys.modules[__name__])
    return MODULE

if __name__ == "__main__":
    main(len(sys.argv),sys.argv)
